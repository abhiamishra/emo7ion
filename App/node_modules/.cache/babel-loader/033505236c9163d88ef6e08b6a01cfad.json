{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\hurle\\\\School\\\\Spring 2022\\\\AIM\\\\emo7ion3\\\\emo7ion\\\\App\\\\src\\\\pages\\\\video.js\";\nimport React from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction Video() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    dangerouslySetInnerHTML: createMarkup()\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 4,\n    columnNumber: 10\n  }, this);\n}\n\n_c = Video;\n\nfunction createMarkup() {\n  return {\n    __html: '<html> <h1>Video</h1> <head> <meta charset=\"UTF-8\"/> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/> <title>Opencv JS</title> <script async src=\"video_files/opencv.js\" onload=\"openCvReady();\"></script> <script src=\"video_files/utils.js\"></script> </head> <body> <video id=\"cam_input\" height=\"240\" width=\"320\"></video> <canvas id=\"canvas_output\"></canvas> </body> <script type=\"text/JavaScript\">function openCvReady() {  cv[\"onRuntimeInitialized\"]=()=>{    let video = document.getElementById(\"cam_input\");  navigator.mediaDevices.getUserMedia({ video: true, audio: false })    .then(function(stream) {        video.srcObject = stream;        video.play();    })    .catch(function(err) {        console.log(\"An error occurred! \" + err);    });    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);    let gray = new cv.Mat();    let cap = new cv.VideoCapture(cam_input);    let faces = new cv.RectVector();    let classifier = new cv.CascadeClassifier();    let utils = new Utils(\"errorMessage\");    let faceCascadeFile = \"haarcascade_frontalface_default.xml\"; utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {    classifier.load(faceCascadeFile); // in the callback, load the cascade from file}); console.log(\"Hello Everybody!\");</script> </html>'\n  };\n}\n\nconst script = document.createElement('script');\nscript.src = '/video_files/opencv.js';\ndocument.head.appendChild(script);\n/*\r\nfunction openCvReady() {\r\n  cv['onRuntimeInitialized']=()=>{\r\n    let video = document.getElementById(\"cam_input\"); // video is the id of video tag\r\n    navigator.mediaDevices.getUserMedia({ video: true, audio: false })\r\n    .then(function(stream) {\r\n        video.srcObject = stream;\r\n        video.play();\r\n    })\r\n    .catch(function(err) {\r\n        console.log(\"An error occurred! \" + err);\r\n    });\r\n    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\r\n    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\r\n    let gray = new cv.Mat();\r\n    let cap = new cv.VideoCapture(cam_input);\r\n    let faces = new cv.RectVector();\r\n    let classifier = new cv.CascadeClassifier();\r\n    let utils = new Utils('errorMessage');\r\n    let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\r\n    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\r\n    classifier.load(faceCascadeFile); // in the callback, load the cascade from file\r\n});\r\n\r\n    const FPS = 40;\r\n    function processVideo() {\r\n\r\n        let canvas = document.getElementById('canvas_output');\r\n        let ctx = canvas.getContext('2d');\r\n\r\n\r\n        let begin = Date.now();\r\n        cap.read(src);\r\n        src.copyTo(dst);\r\n        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\r\n        try{\r\n            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\r\n            console.log(faces.size());\r\n        }catch(err){\r\n            console.log(err);\r\n        }\r\n        for (let i = 0; i < faces.size(); ++i) {\r\n            let face = faces.get(i);\r\n            let point1 = new cv.Point(face.x, face.y);\r\n            let point2 = new cv.Point(face.x + face.width, face.y + face.height);\r\n            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\r\n            //ctx.beginPath();\r\n            //ctx.moveTo(face.x, face.y);\r\n            //ctx.lineTo(face.x + face.width, face.y + face.height);\r\n            //ctx.stroke();\r\n            //ctx.lineWidth = 10;\r\n\r\n            //base_image = new Image();\r\n            //base_image.src = 'emojis/happy.png';\r\n            //base_image.onload = function(){\r\n\r\n              //console.log(\"here\");\r\n            //}\r\n        }\r\n        cv.imshow(\"canvas_output\", dst);\r\n        // schedule next one.\r\n        let delay = 1000/FPS - (Date.now() - begin);\r\n        setTimeout(processVideo, delay);\r\n}\r\n// schedule first one.\r\nsetTimeout(processVideo, 0);\r\n  };\r\n}\r\n*/\n\nexport default Video;\n\nvar _c;\n\n$RefreshReg$(_c, \"Video\");","map":{"version":3,"sources":["C:/Users/hurle/School/Spring 2022/AIM/emo7ion3/emo7ion/App/src/pages/video.js"],"names":["React","Video","createMarkup","__html","script","document","createElement","src","head","appendChild"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;;;AAEA,SAASC,KAAT,GAAgB;AACd,sBAAO;AAAK,IAAA,uBAAuB,EAAEC,YAAY;AAA1C;AAAA;AAAA;AAAA;AAAA,UAAP;AAED;;KAHQD,K;;AAKT,SAASC,YAAT,GAAwB;AACtB,SAAO;AAACC,IAAAA,MAAM,EAAE;AAAT,GAAP;AACD;;AAED,MAAMC,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAf;AACAF,MAAM,CAACG,GAAP,GAAa,wBAAb;AACAF,QAAQ,CAACG,IAAT,CAAcC,WAAd,CAA0BL,MAA1B;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA,eAAeH,KAAf","sourcesContent":["import React from 'react';\r\n\r\nfunction Video(){\r\n  return <div dangerouslySetInnerHTML={createMarkup()} />;\r\n\r\n}\r\n\r\nfunction createMarkup() {\r\n  return {__html: '<html> <h1>Video</h1> <head> <meta charset=\"UTF-8\"/> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/> <title>Opencv JS</title> <script async src=\"video_files/opencv.js\" onload=\"openCvReady();\"></script> <script src=\"video_files/utils.js\"></script> </head> <body> <video id=\"cam_input\" height=\"240\" width=\"320\"></video> <canvas id=\"canvas_output\"></canvas> </body> <script type=\"text/JavaScript\">function openCvReady() {  cv[\"onRuntimeInitialized\"]=()=>{    let video = document.getElementById(\"cam_input\");  navigator.mediaDevices.getUserMedia({ video: true, audio: false })    .then(function(stream) {        video.srcObject = stream;        video.play();    })    .catch(function(err) {        console.log(\"An error occurred! \" + err);    });    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);    let gray = new cv.Mat();    let cap = new cv.VideoCapture(cam_input);    let faces = new cv.RectVector();    let classifier = new cv.CascadeClassifier();    let utils = new Utils(\"errorMessage\");    let faceCascadeFile = \"haarcascade_frontalface_default.xml\"; utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {    classifier.load(faceCascadeFile); // in the callback, load the cascade from file}); console.log(\"Hello Everybody!\");</script> </html>'};\r\n}\r\n\r\nconst script = document.createElement('script');\r\nscript.src = '/video_files/opencv.js';\r\ndocument.head.appendChild(script);\r\n\r\n/*\r\nfunction openCvReady() {\r\n  cv['onRuntimeInitialized']=()=>{\r\n    let video = document.getElementById(\"cam_input\"); // video is the id of video tag\r\n    navigator.mediaDevices.getUserMedia({ video: true, audio: false })\r\n    .then(function(stream) {\r\n        video.srcObject = stream;\r\n        video.play();\r\n    })\r\n    .catch(function(err) {\r\n        console.log(\"An error occurred! \" + err);\r\n    });\r\n    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\r\n    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\r\n    let gray = new cv.Mat();\r\n    let cap = new cv.VideoCapture(cam_input);\r\n    let faces = new cv.RectVector();\r\n    let classifier = new cv.CascadeClassifier();\r\n    let utils = new Utils('errorMessage');\r\n    let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\r\n    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\r\n    classifier.load(faceCascadeFile); // in the callback, load the cascade from file\r\n});\r\n\r\n    const FPS = 40;\r\n    function processVideo() {\r\n\r\n        let canvas = document.getElementById('canvas_output');\r\n        let ctx = canvas.getContext('2d');\r\n\r\n\r\n        let begin = Date.now();\r\n        cap.read(src);\r\n        src.copyTo(dst);\r\n        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\r\n        try{\r\n            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\r\n            console.log(faces.size());\r\n        }catch(err){\r\n            console.log(err);\r\n        }\r\n        for (let i = 0; i < faces.size(); ++i) {\r\n            let face = faces.get(i);\r\n            let point1 = new cv.Point(face.x, face.y);\r\n            let point2 = new cv.Point(face.x + face.width, face.y + face.height);\r\n            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\r\n            //ctx.beginPath();\r\n            //ctx.moveTo(face.x, face.y);\r\n            //ctx.lineTo(face.x + face.width, face.y + face.height);\r\n            //ctx.stroke();\r\n            //ctx.lineWidth = 10;\r\n\r\n            //base_image = new Image();\r\n            //base_image.src = 'emojis/happy.png';\r\n            //base_image.onload = function(){\r\n\r\n              //console.log(\"here\");\r\n            //}\r\n        }\r\n        cv.imshow(\"canvas_output\", dst);\r\n        // schedule next one.\r\n        let delay = 1000/FPS - (Date.now() - begin);\r\n        setTimeout(processVideo, delay);\r\n}\r\n// schedule first one.\r\nsetTimeout(processVideo, 0);\r\n  };\r\n}\r\n*/\r\n\r\n\r\nexport default Video\r\n"]},"metadata":{},"sourceType":"module"}