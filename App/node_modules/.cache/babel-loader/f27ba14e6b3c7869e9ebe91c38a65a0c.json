{"ast":null,"code":"import { AgeGenderNet } from '../ageGenderNet/AgeGenderNet';\nimport { FaceExpressionNet } from '../faceExpressionNet/FaceExpressionNet';\nimport { FaceLandmark68Net } from '../faceLandmarkNet/FaceLandmark68Net';\nimport { FaceLandmark68TinyNet } from '../faceLandmarkNet/FaceLandmark68TinyNet';\nimport { FaceRecognitionNet } from '../faceRecognitionNet/FaceRecognitionNet';\nimport { Mtcnn } from '../mtcnn/Mtcnn';\nimport { SsdMobilenetv1 } from '../ssdMobilenetv1/SsdMobilenetv1';\nimport { TinyFaceDetector } from '../tinyFaceDetector/TinyFaceDetector';\nimport { TinyYolov2 } from '../tinyYolov2';\nexport var nets = {\n  ssdMobilenetv1: new SsdMobilenetv1(),\n  tinyFaceDetector: new TinyFaceDetector(),\n  tinyYolov2: new TinyYolov2(),\n  mtcnn: new Mtcnn(),\n  faceLandmark68Net: new FaceLandmark68Net(),\n  faceLandmark68TinyNet: new FaceLandmark68TinyNet(),\n  faceRecognitionNet: new FaceRecognitionNet(),\n  faceExpressionNet: new FaceExpressionNet(),\n  ageGenderNet: new AgeGenderNet()\n};\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var ssdMobilenetv1 = function (input, options) {\n  return nets.ssdMobilenetv1.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyFaceDetector = function (input, options) {\n  return nets.tinyFaceDetector.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyYolov2 = function (input, options) {\n  return nets.tinyYolov2.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\n\nexport var mtcnn = function (input, options) {\n  return nets.mtcnn.forward(input, options);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarks = function (input) {\n  return nets.faceLandmark68Net.detectLandmarks(input);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarksTiny = function (input) {\n  return nets.faceLandmark68TinyNet.detectLandmarks(input);\n};\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\n\nexport var computeFaceDescriptor = function (input) {\n  return nets.faceRecognitionNet.computeFaceDescriptor(input);\n};\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\n\nexport var recognizeFaceExpressions = function (input) {\n  return nets.faceExpressionNet.predictExpressions(input);\n};\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\n\nexport var predictAgeAndGender = function (input) {\n  return nets.ageGenderNet.predictAgeAndGender(input);\n};\nexport var loadSsdMobilenetv1Model = function (url) {\n  return nets.ssdMobilenetv1.load(url);\n};\nexport var loadTinyFaceDetectorModel = function (url) {\n  return nets.tinyFaceDetector.load(url);\n};\nexport var loadMtcnnModel = function (url) {\n  return nets.mtcnn.load(url);\n};\nexport var loadTinyYolov2Model = function (url) {\n  return nets.tinyYolov2.load(url);\n};\nexport var loadFaceLandmarkModel = function (url) {\n  return nets.faceLandmark68Net.load(url);\n};\nexport var loadFaceLandmarkTinyModel = function (url) {\n  return nets.faceLandmark68TinyNet.load(url);\n};\nexport var loadFaceRecognitionModel = function (url) {\n  return nets.faceRecognitionNet.load(url);\n};\nexport var loadFaceExpressionModel = function (url) {\n  return nets.faceExpressionNet.load(url);\n};\nexport var loadAgeGenderModel = function (url) {\n  return nets.ageGenderNet.load(url);\n}; // backward compatibility\n\nexport var loadFaceDetectionModel = loadSsdMobilenetv1Model;\nexport var locateFaces = ssdMobilenetv1;\nexport var detectLandmarks = detectFaceLandmarks;","map":{"version":3,"mappings":"AAAA,SAASA,YAAT,QAA6B,8BAA7B;AAMA,SAASC,iBAAT,QAAkC,wCAAlC;AAEA,SAASC,iBAAT,QAAkC,sCAAlC;AACA,SAASC,qBAAT,QAAsC,0CAAtC;AACA,SAASC,kBAAT,QAAmC,0CAAnC;AAGA,SAASC,KAAT,QAAsB,gBAAtB;AAEA,SAASC,cAAT,QAA+B,kCAA/B;AAEA,SAASC,gBAAT,QAAiC,sCAAjC;AAEA,SAA6BC,UAA7B,QAA+C,eAA/C;AAEA,OAAO,IAAMC,IAAI,GAAG;AAClBC,gBAAc,EAAE,IAAIJ,cAAJ,EADE;AAElBK,kBAAgB,EAAE,IAAIJ,gBAAJ,EAFA;AAGlBK,YAAU,EAAE,IAAIJ,UAAJ,EAHM;AAIlBK,OAAK,EAAE,IAAIR,KAAJ,EAJW;AAKlBS,mBAAiB,EAAE,IAAIZ,iBAAJ,EALD;AAMlBa,uBAAqB,EAAE,IAAIZ,qBAAJ,EANL;AAOlBa,oBAAkB,EAAE,IAAIZ,kBAAJ,EAPF;AAQlBa,mBAAiB,EAAE,IAAIhB,iBAAJ,EARD;AASlBiB,cAAY,EAAE,IAAIlB,YAAJ;AATI,CAAb;AAYP;;;;;;;;AAOA,OAAO,IAAMU,cAAc,GAAG,UAACS,KAAD,EAAmBC,OAAnB,EAAiD;AAC7E,aAAI,CAACV,cAAL,CAAoBW,WAApB,CAAgCF,KAAhC,EAAuCC,OAAvC;AAA+C,CAD1C;AAGP;;;;;;;;AAOA,OAAO,IAAMT,gBAAgB,GAAG,UAACQ,KAAD,EAAmBC,OAAnB,EAAmD;AACjF,aAAI,CAACT,gBAAL,CAAsBU,WAAtB,CAAkCF,KAAlC,EAAyCC,OAAzC;AAAiD,CAD5C;AAGP;;;;;;;;AAOA,OAAO,IAAMR,UAAU,GAAG,UAACO,KAAD,EAAmBC,OAAnB,EAA8C;AACtE,aAAI,CAACR,UAAL,CAAgBS,WAAhB,CAA4BF,KAA5B,EAAmCC,OAAnC;AAA2C,CADtC;AAGP;;;;;;;;;AAQA,OAAO,IAAMP,KAAK,GAAG,UAACM,KAAD,EAAmBC,OAAnB,EAAwC;AAC3D,aAAI,CAACP,KAAL,CAAWS,OAAX,CAAmBH,KAAnB,EAA0BC,OAA1B;AAAkC,CAD7B;AAGP;;;;;;;;AAOA,OAAO,IAAMG,mBAAmB,GAAG,UAACJ,KAAD,EAAiB;AAClD,aAAI,CAACL,iBAAL,CAAuBU,eAAvB,CAAuCL,KAAvC;AAA6C,CADxC;AAGP;;;;;;;;;;AASA,OAAO,IAAMM,uBAAuB,GAAG,UAACN,KAAD,EAAiB;AACtD,aAAI,CAACJ,qBAAL,CAA2BS,eAA3B,CAA2CL,KAA3C;AAAiD,CAD5C;AAGP;;;;;;;;;;;AAUA,OAAO,IAAMO,qBAAqB,GAAG,UAACP,KAAD,EAAiB;AACpD,aAAI,CAACH,kBAAL,CAAwBU,qBAAxB,CAA8CP,KAA9C;AAAoD,CAD/C;AAIP;;;;;;;;AAOA,OAAO,IAAMQ,wBAAwB,GAAG,UAACR,KAAD,EAAiB;AACvD,aAAI,CAACF,iBAAL,CAAuBW,kBAAvB,CAA0CT,KAA1C;AAAgD,CAD3C;AAGP;;;;;;;;AAOA,OAAO,IAAMU,mBAAmB,GAAG,UAACV,KAAD,EAAiB;AAClD,aAAI,CAACD,YAAL,CAAkBW,mBAAlB,CAAsCV,KAAtC;AAA4C,CADvC;AAGP,OAAO,IAAMW,uBAAuB,GAAG,UAACC,GAAD,EAAY;AAAK,aAAI,CAACrB,cAAL,CAAoBsB,IAApB,CAAyBD,GAAzB;AAA6B,CAA9E;AACP,OAAO,IAAME,yBAAyB,GAAG,UAACF,GAAD,EAAY;AAAK,aAAI,CAACpB,gBAAL,CAAsBqB,IAAtB,CAA2BD,GAA3B;AAA+B,CAAlF;AACP,OAAO,IAAMG,cAAc,GAAG,UAACH,GAAD,EAAY;AAAK,aAAI,CAAClB,KAAL,CAAWmB,IAAX,CAAgBD,GAAhB;AAAoB,CAA5D;AACP,OAAO,IAAMI,mBAAmB,GAAG,UAACJ,GAAD,EAAY;AAAK,aAAI,CAACnB,UAAL,CAAgBoB,IAAhB,CAAqBD,GAArB;AAAyB,CAAtE;AACP,OAAO,IAAMK,qBAAqB,GAAG,UAACL,GAAD,EAAY;AAAK,aAAI,CAACjB,iBAAL,CAAuBkB,IAAvB,CAA4BD,GAA5B;AAAgC,CAA/E;AACP,OAAO,IAAMM,yBAAyB,GAAG,UAACN,GAAD,EAAY;AAAK,aAAI,CAAChB,qBAAL,CAA2BiB,IAA3B,CAAgCD,GAAhC;AAAoC,CAAvF;AACP,OAAO,IAAMO,wBAAwB,GAAG,UAACP,GAAD,EAAY;AAAK,aAAI,CAACf,kBAAL,CAAwBgB,IAAxB,CAA6BD,GAA7B;AAAiC,CAAnF;AACP,OAAO,IAAMQ,uBAAuB,GAAG,UAACR,GAAD,EAAY;AAAK,aAAI,CAACd,iBAAL,CAAuBe,IAAvB,CAA4BD,GAA5B;AAAgC,CAAjF;AACP,OAAO,IAAMS,kBAAkB,GAAG,UAACT,GAAD,EAAY;AAAK,aAAI,CAACb,YAAL,CAAkBc,IAAlB,CAAuBD,GAAvB;AAA2B,CAAvE,C,CAEP;;AACA,OAAO,IAAMU,sBAAsB,GAAGX,uBAA/B;AACP,OAAO,IAAMT,WAAW,GAAGX,cAApB;AACP,OAAO,IAAMc,eAAe,GAAGD,mBAAxB","names":["AgeGenderNet","FaceExpressionNet","FaceLandmark68Net","FaceLandmark68TinyNet","FaceRecognitionNet","Mtcnn","SsdMobilenetv1","TinyFaceDetector","TinyYolov2","nets","ssdMobilenetv1","tinyFaceDetector","tinyYolov2","mtcnn","faceLandmark68Net","faceLandmark68TinyNet","faceRecognitionNet","faceExpressionNet","ageGenderNet","input","options","locateFaces","forward","detectFaceLandmarks","detectLandmarks","detectFaceLandmarksTiny","computeFaceDescriptor","recognizeFaceExpressions","predictExpressions","predictAgeAndGender","loadSsdMobilenetv1Model","url","load","loadTinyFaceDetectorModel","loadMtcnnModel","loadTinyYolov2Model","loadFaceLandmarkModel","loadFaceLandmarkTinyModel","loadFaceRecognitionModel","loadFaceExpressionModel","loadAgeGenderModel","loadFaceDetectionModel"],"sources":["../../../src/globalApi/nets.ts"],"sourcesContent":[null]},"metadata":{},"sourceType":"module"}