{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\hurle\\\\School\\\\Spring 2022\\\\AIM\\\\emo7ion3\\\\emo7ion\\\\App\\\\src\\\\pages\\\\video.js\";\nimport React from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction Video() {\n  return /*#__PURE__*/_jsxDEV(\"html\", {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Video\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"head\", {\n      children: [/*#__PURE__*/_jsxDEV(\"meta\", {\n        charset: \"UTF-8\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 8,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"meta\", {\n        name: \"viewport\",\n        content: \"width=device-width, initial-scale=1.0\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 9,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"title\", {\n        children: \"Opencv JS\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 10,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"script\", {\n        async: true,\n        src: \"video_files/opencv.js\",\n        onload: \"openCvReady();\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 11,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"script\", {\n        src: \"video_files/utils.js\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 12,\n        columnNumber: 13\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 7,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"body\", {\n      children: [/*#__PURE__*/_jsxDEV(\"video\", {\n        id: \"cam_input\",\n        height: \"240\",\n        width: \"320\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 15,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        id: \"canvas_output\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 16,\n        columnNumber: 13\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"script\", {\n      type: \"text/JavaScript\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 5,\n    columnNumber: 9\n  }, this);\n}\n/*\r\nfunction openCvReady() {\r\n  cv['onRuntimeInitialized']=()=>{\r\n    let video = document.getElementById(\"cam_input\"); // video is the id of video tag\r\n    navigator.mediaDevices.getUserMedia({ video: true, audio: false })\r\n    .then(function(stream) {\r\n        video.srcObject = stream;\r\n        video.play();\r\n    })\r\n    .catch(function(err) {\r\n        console.log(\"An error occurred! \" + err);\r\n    });\r\n    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\r\n    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\r\n    let gray = new cv.Mat();\r\n    let cap = new cv.VideoCapture(cam_input);\r\n    let faces = new cv.RectVector();\r\n    let classifier = new cv.CascadeClassifier();\r\n    let utils = new Utils('errorMessage');\r\n    let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\r\n    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\r\n    classifier.load(faceCascadeFile); // in the callback, load the cascade from file\r\n});\r\n    const FPS = 40;\r\n    function processVideo() {\r\n\r\n        let canvas = document.getElementById('canvas_output');\r\n        let ctx = canvas.getContext('2d');\r\n\r\n\r\n        let begin = Date.now();\r\n        cap.read(src);\r\n        src.copyTo(dst);\r\n        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\r\n        try{\r\n            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\r\n            console.log(faces.size());\r\n        }catch(err){\r\n            console.log(err);\r\n        }\r\n        for (let i = 0; i < faces.size(); ++i) {\r\n            let face = faces.get(i);\r\n            let point1 = new cv.Point(face.x, face.y);\r\n            let point2 = new cv.Point(face.x + face.width, face.y + face.height);\r\n            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\r\n            //ctx.beginPath();\r\n            //ctx.moveTo(face.x, face.y);\r\n            //ctx.lineTo(face.x + face.width, face.y + face.height);\r\n            //ctx.stroke();\r\n            //ctx.lineWidth = 10;\r\n\r\n            //base_image = new Image();\r\n            //base_image.src = 'emojis/happy.png';\r\n            //base_image.onload = function(){\r\n\r\n              //console.log(\"here\");\r\n            //}\r\n        }\r\n        cv.imshow(\"canvas_output\", dst);\r\n        // schedule next one.\r\n        let delay = 1000/FPS - (Date.now() - begin);\r\n        setTimeout(processVideo, delay);\r\n}\r\n// schedule first one.\r\nsetTimeout(processVideo, 0);\r\n  };\r\n}\r\n\r\n*/\n\n\n_c = Video;\nexport default Video;\n\nvar _c;\n\n$RefreshReg$(_c, \"Video\");","map":{"version":3,"sources":["C:/Users/hurle/School/Spring 2022/AIM/emo7ion3/emo7ion/App/src/pages/video.js"],"names":["React","Video"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;;;AAEA,SAASC,KAAT,GAAgB;AACZ,sBACI;AAAA,4BACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADA,eAEA;AAAA,8BACI;AAAM,QAAA,OAAO,EAAC;AAAd;AAAA;AAAA;AAAA;AAAA,cADJ,eAEI;AAAM,QAAA,IAAI,EAAC,UAAX;AAAsB,QAAA,OAAO,EAAC;AAA9B;AAAA;AAAA;AAAA;AAAA,cAFJ,eAGI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAHJ,eAII;AAAQ,QAAA,KAAK,MAAb;AAAc,QAAA,GAAG,EAAC,uBAAlB;AAA0C,QAAA,MAAM,EAAC;AAAjD;AAAA;AAAA;AAAA;AAAA,cAJJ,eAKI;AAAQ,QAAA,GAAG,EAAC;AAAZ;AAAA;AAAA;AAAA;AAAA,cALJ;AAAA;AAAA;AAAA;AAAA;AAAA,YAFA,eASA;AAAA,8BACI;AAAO,QAAA,EAAE,EAAC,WAAV;AAAsB,QAAA,MAAM,EAAC,KAA7B;AAAmC,QAAA,KAAK,EAAC;AAAzC;AAAA;AAAA;AAAA;AAAA,cADJ,eAEI;AAAQ,QAAA,EAAE,EAAC;AAAX;AAAA;AAAA;AAAA;AAAA,cAFJ;AAAA;AAAA;AAAA;AAAA;AAAA,YATA,eAaA;AAAQ,MAAA,IAAI,EAAC;AAAb;AAAA;AAAA;AAAA;AAAA,YAbA;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAiBH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;KAvFSA,K;AAyFT,eAAeA,KAAf","sourcesContent":["import React from 'react';\r\n\r\nfunction Video(){\r\n    return(\r\n        <html>\r\n        <h1>Video</h1>\r\n        <head>\r\n            <meta charset=\"UTF-8\"/>\r\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\r\n            <title>Opencv JS</title>\r\n            <script async src=\"video_files/opencv.js\" onload=\"openCvReady();\"></script>\r\n            <script src=\"video_files/utils.js\"></script>\r\n        </head>\r\n        <body>\r\n            <video id=\"cam_input\" height=\"240\" width=\"320\"></video>\r\n            <canvas id=\"canvas_output\"></canvas>\r\n        </body>\r\n        <script type=\"text/JavaScript\"></script>\r\n        </html>\r\n    );\r\n}\r\n/*\r\nfunction openCvReady() {\r\n  cv['onRuntimeInitialized']=()=>{\r\n    let video = document.getElementById(\"cam_input\"); // video is the id of video tag\r\n    navigator.mediaDevices.getUserMedia({ video: true, audio: false })\r\n    .then(function(stream) {\r\n        video.srcObject = stream;\r\n        video.play();\r\n    })\r\n    .catch(function(err) {\r\n        console.log(\"An error occurred! \" + err);\r\n    });\r\n    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\r\n    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\r\n    let gray = new cv.Mat();\r\n    let cap = new cv.VideoCapture(cam_input);\r\n    let faces = new cv.RectVector();\r\n    let classifier = new cv.CascadeClassifier();\r\n    let utils = new Utils('errorMessage');\r\n    let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\r\n    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\r\n    classifier.load(faceCascadeFile); // in the callback, load the cascade from file\r\n});\r\n    const FPS = 40;\r\n    function processVideo() {\r\n\r\n        let canvas = document.getElementById('canvas_output');\r\n        let ctx = canvas.getContext('2d');\r\n\r\n\r\n        let begin = Date.now();\r\n        cap.read(src);\r\n        src.copyTo(dst);\r\n        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\r\n        try{\r\n            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\r\n            console.log(faces.size());\r\n        }catch(err){\r\n            console.log(err);\r\n        }\r\n        for (let i = 0; i < faces.size(); ++i) {\r\n            let face = faces.get(i);\r\n            let point1 = new cv.Point(face.x, face.y);\r\n            let point2 = new cv.Point(face.x + face.width, face.y + face.height);\r\n            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\r\n            //ctx.beginPath();\r\n            //ctx.moveTo(face.x, face.y);\r\n            //ctx.lineTo(face.x + face.width, face.y + face.height);\r\n            //ctx.stroke();\r\n            //ctx.lineWidth = 10;\r\n\r\n            //base_image = new Image();\r\n            //base_image.src = 'emojis/happy.png';\r\n            //base_image.onload = function(){\r\n\r\n              //console.log(\"here\");\r\n            //}\r\n        }\r\n        cv.imshow(\"canvas_output\", dst);\r\n        // schedule next one.\r\n        let delay = 1000/FPS - (Date.now() - begin);\r\n        setTimeout(processVideo, delay);\r\n}\r\n// schedule first one.\r\nsetTimeout(processVideo, 0);\r\n  };\r\n}\r\n\r\n*/\r\n\r\nexport default Video\r\n"]},"metadata":{},"sourceType":"module"}